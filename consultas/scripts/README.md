# ğŸ“ Pipeline de AnÃ¡lise de TranscriÃ§Ãµes com LLM

Sistema automatizado para extrair informaÃ§Ãµes estruturadas de transcriÃ§Ãµes de conversas telefÃ´nicas usando LLM (Large Language Models).

## ğŸ¯ Funcionalidades

O sistema extrai automaticamente as seguintes informaÃ§Ãµes de cada transcriÃ§Ã£o:

1. **Consultor**: Nome do vendedor/atendente
2. **Interlocutor**: Nome do cliente/lead
3. **Assunto**: Tema principal da conversa
4. **Concurso de Interesse**: Concurso pÃºblico mencionado
5. **Oferta Proposta**: Produto/curso oferecido
6. **ObjeÃ§Ã£o**: Principal objeÃ§Ã£o do cliente
7. **Resposta do Consultor**: Como foi tratada a objeÃ§Ã£o

## ğŸš€ ConfiguraÃ§Ã£o Inicial

### 1. Instalar DependÃªncias

Todas as dependÃªncias jÃ¡ foram instaladas, mas caso precise reinstalar:

```bash
pip install python-docx spacy pandas python-dotenv anthropic openai ollama streamlit
```

### 2. Configurar API do LLM

VocÃª tem 3 opÃ§Ãµes de provedor:

#### **OpÃ§Ã£o A: Anthropic Claude (Recomendado - Melhor Qualidade)**

1. Obtenha sua chave em: https://console.anthropic.com/
2. Crie um arquivo `.env` na pasta `consultas/scripts/`:

```bash
cd consultas/scripts/
cp .env.example .env
nano .env  # ou use seu editor preferido
```

3. Adicione sua chave:
```
ANTHROPIC_API_KEY=sk-ant-seu_token_aqui
LLM_PROVIDER=anthropic
```

#### **OpÃ§Ã£o B: OpenAI GPT**

1. Obtenha sua chave em: https://platform.openai.com/api-keys
2. No arquivo `.env`:
```
OPENAI_API_KEY=sk-seu_token_aqui
LLM_PROVIDER=openai
```

#### **OpÃ§Ã£o C: Ollama (Local - GrÃ¡tis)**

1. Instale o Ollama: https://ollama.com/
2. Baixe um modelo:
```bash
ollama pull llama3.2
```
3. No arquivo `.env`:
```
LLM_PROVIDER=ollama
```

## ğŸ“Š Como Usar

### Teste RÃ¡pido (3 transcriÃ§Ãµes)

Primeiro, teste com apenas 3 transcriÃ§Ãµes para validar a configuraÃ§Ã£o:

```bash
cd /home/ulisses/dados_degrau_py
.venv/bin/python consultas/scripts/main_teste.py
```

### Pipeline Completo

Se o teste foi bem-sucedido, processe todas as 45 transcriÃ§Ãµes:

```bash
.venv/bin/python consultas/scripts/main.py
```

### Visualizar Resultados

Inicie a interface web com Streamlit:

```bash
streamlit run consultas/scripts/visualizar_analises.py
```

A interface permite:
- âœ… Visualizar dados estruturados em tabela
- âœ… Filtrar por consultor, concurso, objeÃ§Ãµes
- âœ… Ver mÃ©tricas e estatÃ­sticas
- âœ… GrÃ¡ficos de top consultores e concursos
- âœ… Download dos dados em CSV

## ğŸ“ Estrutura de Arquivos

```
consultas/
â”œâ”€â”€ telefonia/                           # 45 arquivos .docx com transcriÃ§Ãµes
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ processar_transcricoes.py        # LÃª arquivos .docx
â”‚   â”œâ”€â”€ extrair_informacoes_llm.py       # ExtraÃ§Ã£o com LLM
â”‚   â”œâ”€â”€ analisar_dados.py                # Salva em CSV
â”‚   â”œâ”€â”€ main.py                          # Pipeline completo
â”‚   â”œâ”€â”€ main_teste.py                    # Pipeline de teste
â”‚   â”œâ”€â”€ visualizar_analises.py           # Interface Streamlit
â”‚   â”œâ”€â”€ .env.example                     # Exemplo de configuraÃ§Ã£o
â”‚   â””â”€â”€ .env                             # Suas credenciais (criar)
â””â”€â”€ resultados/
    â”œâ”€â”€ analises.csv                     # Output do pipeline completo
    â””â”€â”€ analises_teste.csv               # Output do teste
```

## ğŸ”§ SoluÃ§Ã£o de Problemas

### Erro: "No module named 'anthropic/openai/ollama'"

As dependÃªncias jÃ¡ foram instaladas, mas se precisar reinstalar:
```bash
.venv/bin/pip install anthropic openai ollama
```

### Erro: "ANTHROPIC_API_KEY nÃ£o encontrada"

Certifique-se de:
1. Criar o arquivo `.env` em `consultas/scripts/`
2. Adicionar sua chave no formato correto
3. NÃ£o deixar espaÃ§os antes/depois do `=`

### Erro: "Can't find model 'llama3.2'" (Ollama)

Baixe o modelo primeiro:
```bash
ollama pull llama3.2
```

### Resultados ruins com Ollama

Modelos locais (Ollama) podem ter qualidade inferior. Considere usar Claude ou GPT para melhor precisÃ£o.

## ğŸ’° Custos Estimados

- **Anthropic Claude**: ~$0.01 por transcriÃ§Ã£o (mais preciso)
- **OpenAI GPT-4o-mini**: ~$0.005 por transcriÃ§Ã£o
- **Ollama**: GrÃ¡tis (modelo local, qualidade pode variar)

Para 45 transcriÃ§Ãµes:
- Claude: ~$0.45
- GPT: ~$0.23
- Ollama: $0 (grÃ¡tis)

## ğŸ“ PrÃ³ximos Passos

1. âœ… Configurar API do LLM
2. âœ… Executar teste com 3 transcriÃ§Ãµes
3. âœ… Validar qualidade dos resultados
4. âœ… Executar pipeline completo
5. âœ… Analisar dados no Streamlit
6. ğŸ”„ Ajustar prompt se necessÃ¡rio
7. ğŸ”„ Processar novas transcriÃ§Ãµes periodicamente

## ğŸ“ Notas

- O processamento pode levar alguns minutos dependendo do nÃºmero de transcriÃ§Ãµes
- Os dados sÃ£o salvos em CSV para fÃ¡cil integraÃ§Ã£o com outras ferramentas
- A interface Streamlit atualiza automaticamente quando o CSV Ã© modificado
- Para privacidade mÃ¡xima, use Ollama (modelos locais)
