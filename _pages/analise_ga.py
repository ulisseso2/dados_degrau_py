import streamlit as st
import pandas as pd
import plotly.express as px
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import RunReportRequest, DateRange, Dimension, Metric, FilterExpression, Filter
from google.ads.googleads.client import GoogleAdsClient
from google.ads.googleads.errors import GoogleAdsException
from google.oauth2 import service_account
from dotenv import load_dotenv
import yaml
import os
from datetime import datetime
from st_aggrid import GridOptionsBuilder, AgGrid
from utils.sql_loader import carregar_dados
import time
from gclid_db import (
    load_gclid_cache,
    save_gclid_cache_batch,
    get_campaign_for_gclid,
    get_not_found_gclids,
    get_gclids_by_date_range,
    count_not_found_gclids,
    has_valid_campaign_history,
    restore_valid_gclids,
)

import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

BATCH_SIZE = 1000  # Aumentamos o tamanho do lote
REQUEST_DELAY = 1  # Delay entre requests em segundos

# Carrega as vari√°veis de ambiente do arquivo .env
load_dotenv()

# 1. FUN√á√ïES AUXILIARES

# Carrega as credenciais do Google Analytics de forma h√≠brida
def get_ga_credentials():
    """Carrega as credenciais de forma h√≠brida"""
    try:
        creds_dict = st.secrets["gcp_service_account"]
        return service_account.Credentials.from_service_account_info(creds_dict)
    except (st.errors.StreamlitAPIException, KeyError):
        file_path = os.getenv("GCP_SERVICE_ACCOUNT_FILE")
        if file_path and os.path.exists(file_path):
            return service_account.Credentials.from_service_account_file(file_path)
    return None

@st.cache_resource
def get_google_ads_client():
    """
    Inicializa o cliente do Google Ads para a empresa Degrau.
    Usa cache para evitar reinicializa√ß√µes repetidas.
    Retorna (client, query_customer_id) em caso de sucesso, e (None, None) em caso de falha.
    """
    config = None
    source = ""
    
    # Usa credenciais da Degrau
    yaml_filename = "google-ads.yaml"
    secrets_key = "google_ads"

    try:
        # Tenta carregar do Streamlit Secrets primeiro
        config_raw = st.secrets[secrets_key]
        # Converte para dict se necess√°rio
        if hasattr(config_raw, 'to_dict'):
            config = config_raw.to_dict()
        else:
            config = dict(config_raw)
        source = f"Streamlit Secrets ({secrets_key})"
        st.success(f"Credenciais do Google Ads encontradas no {source}.")
    except (st.errors.StreamlitAPIException, KeyError):
        # Fallback para o arquivo yaml local
        st.info(f"Credenciais do Streamlit Secrets n√£o encontradas. Tentando carregar do arquivo {yaml_filename}...")
        if os.path.exists(yaml_filename):
            try:
                with open(yaml_filename, 'r') as f:
                    config = yaml.safe_load(f)
                source = f"arquivo {yaml_filename}"
                st.success(f"Credenciais do Google Ads carregadas do {source}.")
            except Exception as e:
                st.error(f"Erro ao carregar ou processar o arquivo {yaml_filename}: {e}")
                return None, None
        else:
            st.error(f"Nenhuma fonte de credenciais do Google Ads foi encontrada para Degrau (nem Secrets, nem {yaml_filename}).")
            return None, None

    # Valida√ß√£o unificada das credenciais
    if not isinstance(config, dict):
        st.error(f"Configura√ß√£o inv√°lida carregada de '{source}'. Esperado um dicion√°rio.")
        return None, None
        
    login_customer_id = config.get("login_customer_id")
    if not login_customer_id:
        st.error(f"A chave 'login_customer_id' (MCC ID) est√° ausente em '{source}'.")
        return None, None

    query_customer_id = config.get("customer_id")
    if not query_customer_id:
        st.error(f"A chave 'customer_id' (ID da conta a ser consultada) est√° ausente em '{source}'.")
        return None, None

    try:
        # Inicializa o cliente com a configura√ß√£o completa
        client = GoogleAdsClient.load_from_dict(config)
        # Retorna o cliente e o ID da conta a ser consultada
        return client, str(query_customer_id).replace("-", "")
    except Exception as e:
        st.error(f"Falha ao inicializar o cliente do Google Ads com as credenciais de '{source}': {e}")
        return None, None

def get_google_ads_campaign_performance(client, customer_id, start_date, end_date):
    """
    Fun√ß√£o para buscar dados de desempenho de campanhas diretamente do Google Ads.
    Retorna informa√ß√µes de campanhas, incluindo custo e convers√µes.
    """
    try:
        # Inicializa o servi√ßo
        ga_service = client.get_service("GoogleAdsService")
        
        # Formata as datas para o formato esperado pelo Google Ads (YYYY-MM-DD)
        start_date_str = start_date.strftime('%Y-%m-%d')
        end_date_str = end_date.strftime('%Y-%m-%d')
        
        # Query GAQL (Google Ads Query Language)
        query = f"""
            SELECT 
                campaign.name, 
                campaign.id, 
                metrics.cost_micros, 
                metrics.conversions,
                metrics.conversions_value
            FROM campaign
            WHERE 
                segments.date >= '{start_date_str}' 
                AND segments.date <= '{end_date_str}'
                AND campaign.status != 'REMOVED'
            ORDER BY metrics.cost_micros DESC
        """
        
        # Executa a consulta
        response = ga_service.search_stream(customer_id=customer_id, query=query)
        
        # Processa os resultados
        campaigns_data = []
        
        for batch in response:
            for row in batch.results:
                # Converte micros (millionths) para valores reais e arredonda para 2 casas decimais
                cost = round(float(row.metrics.cost_micros) / 1000000, 2)
                conversions = float(row.metrics.conversions)
                conversion_value = float(row.metrics.conversions_value)
                
                # Calcula CPA (Custo por Convers√£o) e arredonda para 2 casas decimais
                cpa = round(cost / conversions, 2) if conversions > 0 else 0
                
                # Extrai nome do curso venda do nome da campanha (se existir no formato {Curso})
                campaign_name = row.campaign.name
                
                campaigns_data.append({
                    'Campanha': campaign_name,
                    'ID da Campanha': row.campaign.id,
                    'Custo': cost,
                    'Convers√µes': conversions,
                    'Valor de Convers√µes': conversion_value,
                    'CPA (Custo por Convers√£o)': cpa
                })
        
        # Retorna como DataFrame
        return pd.DataFrame(campaigns_data)
    
    except GoogleAdsException as ex:
        error_messages = []
        for error in ex.failure.errors:
            error_messages.append(f"Erro {error.error_code.error_code}: {error.message}")
        st.error("\n".join(error_messages))
        return pd.DataFrame()
    
    except Exception as e:
        st.error(f"Erro na consulta do Google Ads: {str(e)}")
        return pd.DataFrame()

def get_campaigns_for_gclids_with_date(client, customer_id, gclid_date_dict):
    """
    Vers√£o otimizada com:
    - Rate limiting
    - Cache integrado
    - Batch processing eficiente
    """
    if not isinstance(gclid_date_dict, dict) or not gclid_date_dict:
        return {}

    ga_service = client.get_service("GoogleAdsService")
    gclid_campaign_map = {}
    batches_processed = 0
    total_gclids = len(gclid_date_dict)

    # Carrega cache existente
    cache = st.session_state.gclid_cache
    
    # Filtra apenas GCLIDs n√£o consultados OU que est√£o como 'N√£o encontrado'
    # NUNCA reprocessa GCLIDs que j√° t√™m uma campanha v√°lida
    gclids_to_query = {
        gclid: date for gclid, date in gclid_date_dict.items() 
        if gclid not in cache or cache[gclid] == 'N√£o encontrado'
    }
    
    if not gclids_to_query:
        st.info("Todos os GCLIDs j√° foram consultados anteriormente.")
        return {}

    # Agrupa por data para otimizar consultas
    date_groups = {}
    for gclid, date in gclids_to_query.items():
        date_str = date.strftime('%Y-%m-%d')
        date_groups.setdefault(date_str, []).append(gclid)

    progress_bar = st.progress(0)
    status_text = st.empty()

    try:
        for date_str, gclids in date_groups.items():
            for i in range(0, len(gclids), BATCH_SIZE):
                batch = gclids[i:i + BATCH_SIZE]
                unique_gclids = list(set(filter(None, batch)))
                
                if not unique_gclids:
                    continue

                # Rate limiting
                if batches_processed > 0 and batches_processed % 50 == 0:
                    time.sleep(60)  # Pausa a cada 50 batches
                
                # Atualiza UI
                progress = (batches_processed * BATCH_SIZE) / total_gclids
                progress_bar.progress(min(progress, 1.0))
                status_text.text(f"Processando {batches_processed * BATCH_SIZE}/{total_gclids} GCLIDs...")
                
                query = f"""
                    SELECT 
                        campaign.name, 
                        click_view.gclid
                    FROM click_view
                    WHERE click_view.gclid IN ('{"','".join(unique_gclids)}')
                    AND segments.date = '{date_str}'
                    LIMIT {len(unique_gclids)}
                """

                try:
                    stream = ga_service.search_stream(
                        customer_id=customer_id, 
                        query=query
                    )

                    for response in stream:
                        for row in response.results:
                            gclid = row.click_view.gclid
                            campaign_name = row.campaign.name
                            if gclid and campaign_name:  # Valida√ß√£o adicional
                                gclid_campaign_map[gclid] = campaign_name
                                st.session_state.gclid_cache[gclid] = campaign_name  # Atualiza cache

                    batches_processed += 1
                    time.sleep(REQUEST_DELAY)  # Delay entre requests

                except GoogleAdsException as ex:
                    st.error(f"Erro no lote {batches_processed}:")
                    for error in ex.failure.errors:
                        st.error(f"{error.message}")
                    continue

        # Atualiza cache para GCLIDs n√£o encontrados
        for gclid in gclids_to_query:
            if gclid not in gclid_campaign_map:
                cache[gclid] = 'N√£o encontrado'

        # Salva cache no banco de dados - APENAS OS ENCONTRADOS
        if gclid_campaign_map:
            save_gclid_cache_batch(gclid_campaign_map)
            
        # Marca como 'N√£o encontrado' APENAS se nunca foi encontrado antes
        not_found = {}
        for gclid in gclids_to_query:
            if gclid not in gclid_campaign_map:
                # Verifica se j√° existe no banco com campanha v√°lida
                existing_campaign = get_campaign_for_gclid(gclid)
                if existing_campaign and existing_campaign != 'N√£o encontrado':
                    # J√° foi encontrado antes, restaura no cache
                    st.session_state.gclid_cache[gclid] = existing_campaign
                else:
                    # Nunca foi encontrado, marca como n√£o encontrado
                    not_found[gclid] = 'N√£o encontrado'
                    
        if not_found:
            save_gclid_cache_batch(not_found)
            for gclid in not_found:
                st.session_state.gclid_cache[gclid] = 'N√£o encontrado'

        return gclid_campaign_map

    except Exception as e:
        logger.error(f"Erro na consulta: {str(e)}", exc_info=True)
        st.error(f"Erro na consulta: {str(e)}")
        return None
    finally:
        progress_bar.empty()
        status_text.empty()

def reprocess_not_found_gclids(client, customer_id, start_date, end_date, force_all=False):
    """
    Reprocessa GCLIDs marcados como 'N√£o encontrado' tentando encontr√°-los novamente.
    
    Args:
        client: Cliente do Google Ads
        customer_id: ID do cliente
        start_date: Data de in√≠cio
        end_date: Data de fim
        force_all: Se True, reprocessa todos os GCLIDs n√£o encontrados, sen√£o apenas os do per√≠odo
    """
    if force_all:
        not_found_list = get_not_found_gclids()
        st.info(f"Reprocessando {len(not_found_list)} GCLIDs n√£o encontrados...")
    else:
        not_found_list = get_gclids_by_date_range(start_date, end_date)
        st.info(f"Reprocessando {len(not_found_list)} GCLIDs n√£o encontrados no per√≠odo selecionado...")
    
    if not not_found_list:
        st.success("N√£o h√° GCLIDs n√£o encontrados para reprocessar!")
        return {"success": 0, "still_not_found": 0}
    
    # Cria um dicion√°rio com os GCLIDs e suas datas para usar a fun√ß√£o existente
    gclid_date_dict = {}
    for gclid, last_updated in not_found_list:
        # Tenta usar uma data ampla para maximizar as chances de encontrar
        try:
            if isinstance(last_updated, str):
                date_obj = datetime.fromisoformat(last_updated.replace('Z', '+00:00')).date()
            else:
                date_obj = last_updated.date() if hasattr(last_updated, 'date') else start_date
        except:
            date_obj = start_date
            
        gclid_date_dict[gclid] = date_obj
    
    # Remove temporariamente os GCLIDs do cache para for√ßar nova consulta
    original_cache = st.session_state.gclid_cache.copy()
    for gclid in gclid_date_dict.keys():
        if gclid in st.session_state.gclid_cache:
            del st.session_state.gclid_cache[gclid]
    
    try:
        # Usa a fun√ß√£o existente para buscar novamente
        results = get_campaigns_for_gclids_with_date(client, customer_id, gclid_date_dict)
        
        success_count = len(results) if results else 0
        still_not_found = len(gclid_date_dict) - success_count
        
        # Atualiza o cache e banco de dados com os resultados
        if results:
            for gclid, campaign in results.items():
                st.session_state.gclid_cache[gclid] = campaign
            save_gclid_cache_batch(results)
            st.success(f"‚úÖ {success_count} GCLIDs foram encontrados e atualizados!")
        
        if still_not_found > 0:
            st.warning(f"‚ö†Ô∏è {still_not_found} GCLIDs ainda n√£o foram encontrados.")
        
        return {"success": success_count, "still_not_found": still_not_found}
        
    except Exception as e:
        # Restaura o cache original em caso de erro
        st.session_state.gclid_cache.update(original_cache)
        st.error(f"Erro durante o reprocessamento: {str(e)}")
        return {"success": 0, "still_not_found": len(gclid_date_dict)}

def get_individual_conversion_report(client, property_id, start_date, end_date):
    """
    Busca uma lista de eventos individuais que possuem um ID de Transa√ß√£o,
    mostrando o ID da Transa√ß√£o e a campanha, origem e m√≠dia associadas.
    """
    try:
        request = RunReportRequest(
            property=f"properties/{property_id}",
            dimensions=[
                Dimension(name="dateHourMinute"),
                Dimension(name="transactionId"),
                Dimension(name="campaignName"),
                Dimension(name="source"),
                Dimension(name="medium"),
            ],
            metrics=[Metric(name="eventCount")],
            date_ranges=[DateRange(start_date=start_date.strftime('%Y-%m-%d'), end_date=end_date.strftime('%Y-%m-%d'))],
            # Filtro para pegar apenas eventos que tenham um transaction_id
            dimension_filter=FilterExpression(
                filter=Filter(
                    field_name="transactionId",
                    string_filter=Filter.StringFilter(
                        value="",
                        match_type=Filter.StringFilter.MatchType.FULL_REGEXP,
                        case_sensitive=False
                    ),
                    not_expression=True # Pega onde transactionId N√ÉO √© ""
                )
            ),
            limit=25000 # Um limite alto para capturar todos os eventos com ID de transa√ß√£o do per√≠odo
        )
        response = client.run_report(request)
        
        if response and response.rows:
            rows = []
            for r in response.rows:
                datetime_str = r.dimension_values[0].value
                datetime_obj = datetime.strptime(datetime_str, '%Y%m%d%H%M')

                rows.append({
                    'Data (GA4)': datetime_obj,
                    'ID da Transa√ß√£o': r.dimension_values[1].value,
                    'Campanha (GA4)': r.dimension_values[2].value,
                    'Origem (GA4)': r.dimension_values[3].value,
                    'M√≠dia (GA4)': r.dimension_values[4].value,
                })
            # Remove duplicatas, mantendo a primeira ocorr√™ncia (a mais prov√°vel de ser a correta)
            df = pd.DataFrame(rows)
            return df.drop_duplicates(subset=['ID da Transa√ß√£o'], keep='first')

    except Exception as e:
        st.warning(f"Erro ao buscar o relat√≥rio de convers√µes individuais: {e}")
        
    return pd.DataFrame()
# Fun√ß√£o para executar relat√≥rios no GA4
def run_ga_report(client, property_id, dimensions, metrics, start_date, end_date, limit=15, order_bys=None):
    """Fun√ß√£o √öNICA para executar qualquer relat√≥rio no GA4."""
    try:
        request = RunReportRequest(
            property=f"properties/{property_id}",
            dimensions=dimensions,
            metrics=metrics,
            date_ranges=[DateRange(start_date=start_date.strftime('%Y-%m-%d'), end_date=end_date.strftime('%Y-%m-%d'))],
            limit=limit,
            order_bys=order_bys if order_bys else []
        )
        return client.run_report(request)
    except Exception as e:
        st.warning(f"Aten√ß√£o: A consulta ao Google Analytics falhou. Erro: {e}")
        return None

def formatar_reais(valor):
    """Formata um n√∫mero para o padr√£o monet√°rio brasileiro."""
    if pd.isna(valor) or valor == 0: return "R$ 0,00"
    return f"R$ {valor:,.2f}".replace(",", "X").replace(".", ",").replace("X", ".")


# 2. FUN√á√ÉO PRINCIPAL DA P√ÅGINA (run_page)

def run_page():
    st.title("üìä An√°lise de Performance Digital (GA4)")

    PROPERTY_ID = "327463413"
    credentials = get_ga_credentials()

    if not credentials:
        st.error("Falha na autentica√ß√£o com o Google. Verifique as configura√ß√µes de segredos ou o arquivo .env.")
        st.stop()
        
    client = BetaAnalyticsDataClient(credentials=credentials)

    # --- FILTRO DE DATA √öNICO E GLOBAL PARA A P√ÅGINA ---
    st.sidebar.header("Filtro de Per√≠odo")
    hoje = datetime.now().date()
    data_inicio_padrao = hoje - pd.Timedelta(days=27)
    
    periodo_selecionado = st.sidebar.date_input(
        "Selecione o Per√≠odo de An√°lise:",
        [data_inicio_padrao, hoje],
        key="ga_date_range"
    )

    if len(periodo_selecionado) != 2:
        st.warning("Por favor, selecione um per√≠odo de datas v√°lido na barra lateral.")
        st.stop()
    
    start_date, end_date = periodo_selecionado
    st.info(f"Exibindo dados de **{start_date.strftime('%d/%m/%Y')}** a **{end_date.strftime('%d/%m/%Y')}**")
 
    # --- AN√ÅLISE 1: PERFORMANCE DE CAMPANHAS ---
    cost_response = run_ga_report(
        client, PROPERTY_ID,
        dimensions=[Dimension(name="campaignName")],
        metrics=[Metric(name="advertiserAdCost"), Metric(name="conversions")],
        start_date=start_date, end_date=end_date,
        order_bys=[{'metric': {'metric_name': 'advertiserAdCost'}, 'desc': True}]
    )

    if cost_response and cost_response.rows:
        rows = []
        for r in cost_response.rows:
            cost = float(r.metric_values[0].value)
            conversions = float(r.metric_values[1].value)
            cpa = (cost / conversions) if conversions > 0 else 0
            rows.append({'Campanha': r.dimension_values[0].value, 'Custo': cost, 'Convers√µes': int(conversions), 'CPA (Custo por Convers√£o)': cpa})
        
        df_performance = pd.DataFrame(rows)
        df_performance = df_performance[df_performance['Custo'] > 0].reset_index(drop=True)

        # M√©trica de Custo Total ---
        custo_total_periodo = df_performance['Custo'].sum()
        st.metric("Custo Total no Per√≠odo", formatar_reais(custo_total_periodo))


    st.header("üìà Performance de Campanhas por Curso Venda (Dados do GA4)")

    if not df_performance.empty:
        # --- 1. EXTRA√á√ÉO DO "CURSO VENDA" ---
        df_agrupado = df_performance.copy()
        
        # Usa regex para extrair o conte√∫do dentro de {}
        df_agrupado['Curso Venda'] = df_agrupado['Campanha'].str.extract(r'\{(.*?)\}')
        
        # Se alguma campanha n√£o tiver o padr√£o, preenche com um valor padr√£o
        df_agrupado['Curso Venda'] = df_agrupado['Curso Venda'].fillna('N√£o Especificado')
        
        st.info("Esta tabela agrupa as campanhas pelo 'Curso Venda' extra√≠do do nome. Clique na seta (‚ñ∂) para expandir e ver os detalhes. Dados provenientes do GA4.")

        # --- 2. CONFIGURA√á√ÉO DA TABELA HIER√ÅRQUICA AG-GRID ---
        gb = GridOptionsBuilder.from_dataframe(df_agrupado)

        # Configura a coluna "Curso Venda" para ser o grupo
        gb.configure_column("Curso Venda", rowGroup=True, hide=True)
        
        # Configura as outras colunas
        gb.configure_column("Campanha", header_name="Nome da Campanha")
        gb.configure_column(
            "Custo", header_name="Custo", type=["numericColumn", "numberColumnFilter", "customNumericFormat"],
            aggFunc='sum',
        )
        gb.configure_column(
            "Convers√µes", header_name="Convers√µes", type=["numericColumn", "numberColumnFilter", "customNumericFormat"],
            aggFunc='sum',

        )
        gb.configure_column(
            "CPA (Custo por Convers√£o)", header_name="CPA", type=["numericColumn", "numberColumnFilter", "customNumericFormat"],
            # Calcula o CPA agregado para o grupo
            valueGetter='(params.node.aggData.Custo && params.node.aggData.Convers√µes) ? params.node.aggData.Custo / params.node.aggData.Convers√µes : null',
            valueFormatter="data['CPA (Custo por Convers√£o)'] ? data['CPA (Custo por Convers√£o)'].toLocaleString('pt-BR', {style: 'currency', currency: 'BRL'}) : ''"
        )
        
        grid_options = gb.build()
        
        # Define a apar√™ncia da coluna de grupo
        grid_options["autoGroupColumnDef"] = {
            "headerName": "Curso Venda (Produto)",
            "minWidth": 250,
            "cellRendererParams": {"suppressCount": True}
        }
        

        # --- 3. EXIBI√á√ÉO DA TABELA ---
        AgGrid(
            df_agrupado,
            gridOptions=grid_options,
            width='100%',
            theme='streamlit',
            allow_unsafe_jscode=True,
            enable_enterprise_modules=True
        )
    else:
        st.info("N√£o h√° dados de performance para agrupar por Curso Venda.")
        
    # --- NOVA SE√á√ÉO: TABELA DO GOOGLE ADS ---
    st.header("üìä Performance de Campanhas por Curso Venda (Dados do Google Ads)")
    
    # Obt√©m cliente do Google Ads
    gads_client, customer_id = get_google_ads_client()
    
    if gads_client and customer_id:
        # Busca dados diretamente do Google Ads
        with st.spinner("Buscando dados de campanhas no Google Ads..."):
            df_gads = get_google_ads_campaign_performance(gads_client, customer_id, start_date, end_date)
            
        if not df_gads.empty:
            # Filtra apenas campanhas com valor investido (Custo > 0)
            df_gads = df_gads[df_gads['Custo'] > 0].copy()
            # Extrai o "Curso Venda" do nome da campanha (similar ao GA4)
            df_gads['Curso Venda'] = df_gads['Campanha'].str.extract(r'\{(.*?)\}')
            df_gads['Curso Venda'] = df_gads['Curso Venda'].fillna('N√£o Especificado')
            # Formata o custo para duas casas decimais com ponto
            df_gads['Custo'] = df_gads['Custo'].map(lambda x: float(f"{x:.2f}"))
            
            # Formatamos os dados agregados (somas por grupo) para garantir duas casas decimais
            df_gads_grouped = df_gads.groupby('Curso Venda')['Custo'].sum().reset_index()
            df_gads_grouped['Custo'] = df_gads_grouped['Custo'].map(lambda x: float(f"{x:.2f}"))
            
            st.info("Esta tabela agrupa as campanhas pelo 'Curso Venda' extra√≠do do nome. Clique na seta (‚ñ∂) para expandir e ver os detalhes. Dados provenientes diretamente do Google Ads API.")
            # Configura√ß√£o da tabela hier√°rquica AG-GRID
            gb_gads = GridOptionsBuilder.from_dataframe(df_gads)
            # Configura a coluna "Curso Venda" para ser o grupo
            gb_gads.configure_column("Curso Venda", rowGroup=True, hide=True)
            # Configura as outras colunas
            gb_gads.configure_column("Campanha", header_name="Nome da Campanha")
            gb_gads.configure_column("ID da Campanha", hide=True)
            gb_gads.configure_column(
                "Custo", header_name="Custo", type=["numericColumn", "numberColumnFilter", "customNumericFormat"],
                aggFunc='sum',
                valueFormatter="Number(data.Custo).toLocaleString('en-US', {minimumFractionDigits: 2, maximumFractionDigits: 2})"
            )
            gb_gads.configure_column(
                "Convers√µes", header_name="Convers√µes", type=["numericColumn", "numberColumnFilter", "customNumericFormat"],
                aggFunc='sum'
            )
            gb_gads.configure_column(
                "CPA (Custo por Convers√£o)", header_name="CPA", type=["numericColumn", "numberColumnFilter", "customNumericFormat"],
                # Calcula o CPA agregado para o grupo
                valueGetter='(params.node.aggData.Custo && params.node.aggData.Convers√µes && params.node.aggData.Convers√µes > 0) ? Math.round((params.node.aggData.Custo / params.node.aggData.Convers√µes) * 100) / 100 : null',
                valueFormatter="data['CPA (Custo por Convers√£o)'] ? Number(data['CPA (Custo por Convers√£o)']).toLocaleString('en-US', {minimumFractionDigits: 2, maximumFractionDigits: 2}) : ''"
            )
            grid_options_gads = gb_gads.build()
            # Define a apar√™ncia da coluna de grupo
            grid_options_gads["autoGroupColumnDef"] = {
                "headerName": "Curso Venda (Produto)",
                "minWidth": 250,
                "cellRendererParams": {"suppressCount": True}
            }
            # Exibi√ß√£o da tabela
            AgGrid(
                df_gads,
                gridOptions=grid_options_gads,
                width='100%',
                theme='streamlit',
                allow_unsafe_jscode=True,
                enable_enterprise_modules=True
            )
            # Adiciona uma exibi√ß√£o de dados brutos das campanhas
            st.header("üìä Performance de Campanhas (Dados Brutos do Google Ads)")
            st.info("Esta tabela mostra os dados de custo e convers√£o diretamente do Google Ads, sem agrupamentos.")
            
            # Formata as colunas de valor para garantir exatamente 2 casas decimais
            df_bruto = df_gads.copy()
            df_bruto['Custo'] = df_bruto['Custo'].apply(lambda x: round(x, 2))
            df_bruto['CPA (Custo por Convers√£o)'] = df_bruto['CPA (Custo por Convers√£o)'].apply(lambda x: round(x, 2) if x > 0 else 0)
            
            st.dataframe(
                df_bruto.sort_values("Custo", ascending=False),
                use_container_width=True,
                hide_index=True,
                column_config={
                    "Custo": st.column_config.NumberColumn(format="%.2f"),
                    "CPA (Custo por Convers√£o)": st.column_config.NumberColumn(format="%.2f")
                }
            )
        else:
            st.warning("N√£o foi poss√≠vel obter dados de campanhas do Google Ads para o per√≠odo selecionado.")
    else:
        st.error("N√£o foi poss√≠vel conectar ao Google Ads. Verifique as credenciais.")

    # --- SE√á√ÉO: REPROCESSAMENTO DE GCLIDs N√ÉO ENCONTRADOS ---
    st.header("üîÑ Reprocessamento de GCLIDs")
    
    # Mostra estat√≠sticas dos GCLIDs n√£o encontrados
    total_not_found = count_not_found_gclids()
    period_not_found = get_gclids_by_date_range(start_date, end_date)
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Total de GCLIDs N√£o Encontrados", total_not_found)
    with col2:
        st.metric("N√£o Encontrados no Per√≠odo", len(period_not_found))
    
    if total_not_found > 0:
        st.info("Os GCLIDs marcados como 'N√£o encontrado' podem ter sido processados em momentos diferentes ou podem ter se tornado dispon√≠veis na API do Google Ads.")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üîÑ Reprocessar Per√≠odo Atual", help="Reprocessa apenas os GCLIDs n√£o encontrados no per√≠odo selecionado"):
                if gads_client and customer_id:
                    with st.spinner("Reprocessando GCLIDs do per√≠odo..."):
                        results = reprocess_not_found_gclids(gads_client, customer_id, start_date, end_date, force_all=False)
                        if results["success"] > 0:
                            st.rerun()  # Recarrega a p√°gina para mostrar os dados atualizados
                else:
                    st.error("Cliente Google Ads n√£o dispon√≠vel.")
        
        with col2:
            if st.button("üîÑ Reprocessar Todos", help="Reprocessa todos os GCLIDs n√£o encontrados (pode demorar)"):
                if gads_client and customer_id:
                    with st.spinner("Reprocessando todos os GCLIDs n√£o encontrados..."):
                        results = reprocess_not_found_gclids(gads_client, customer_id, start_date, end_date, force_all=True)
                        if results["success"] > 0:
                            st.rerun()  # Recarrega a p√°gina para mostrar os dados atualizados
                else:
                    st.error("Cliente Google Ads n√£o dispon√≠vel.")
    else:
        st.success("üéâ N√£o h√° GCLIDs marcados como 'N√£o encontrado'!")

    st.divider()

        # SE√á√ÉO: KPIs GERAIS DE ENGAJAMENTO ---
    st.header("Vis√£o Geral do Per√≠odo")
    
    kpi_response = run_ga_report(client, PROPERTY_ID, [], 
        [Metric(name="activeUsers"), Metric(name="newUsers"), Metric(name="screenPageViews"), Metric(name="eventCount"), Metric(name="userEngagementDuration")],
        start_date, end_date, limit=1)

    if kpi_response and kpi_response.rows:
        row = kpi_response.rows[0]
        usuarios_ativos = int(row.metric_values[0].value)
        novos_usuarios = int(row.metric_values[1].value)
        visualizacoes = int(row.metric_values[2].value)
        eventos = int(row.metric_values[3].value)
        duracao_total_engajamento = float(row.metric_values[4].value)

        # Calcula o tempo m√©dio de engajamento por usu√°rio
        tempo_medio_engajamento = (duracao_total_engajamento / usuarios_ativos) if usuarios_ativos > 0 else 0
        minutos = int(tempo_medio_engajamento // 60)
        segundos = int(tempo_medio_engajamento % 60)
        
        col1, col2, col3, col4, col5 = st.columns(5)
        col1.metric("Usu√°rios Ativos", f"{usuarios_ativos:,}".replace(",", "."))
        col2.metric("Novos Usu√°rios", f"{novos_usuarios:,}".replace(",", "."))
        col3.metric("Visualiza√ß√µes", f"{visualizacoes:,}".replace(",", "."))
        col4.metric("Total de Eventos", f"{eventos:,}".replace(",", "."))
        col5.metric("Tempo M√©dio de Engajamento", f"{minutos:02d}:{segundos:02d} min")
    else:
        st.info("N√£o foi poss√≠vel carregar os KPIs.")

    st.divider()

    # SE√á√ÉO: TABELA DE AQUISI√á√ÉO DE TR√ÅFEGO ---
    st.header("üìà Aquisi√ß√£o de Tr√°fego por Canal")

    acq_response = run_ga_report(client, PROPERTY_ID, 
        [Dimension(name="sessionDefaultChannelGroup")], 
        [Metric(name="sessions"), Metric(name="activeUsers"), Metric(name="conversions"), Metric(name="purchaseRevenue")], 
        start_date, end_date)
 
    if acq_response and acq_response.rows:
        rows = []
        for r in acq_response.rows:
            rows.append({
                'Canal': r.dimension_values[0].value,
                'Sess√µes': int(r.metric_values[0].value),
                'Usu√°rios': int(r.metric_values[1].value),
                'Convers√µes': int(r.metric_values[2].value),
                'Receita (R$)': float(r.metric_values[3].value)
            })
        
        df_acquisition = pd.DataFrame(rows).sort_values("Sess√µes", ascending=False)
        
        st.dataframe(df_acquisition, use_container_width=True, hide_index=True,
            column_config={
                "Receita (R$)": st.column_config.NumberColumn(format="R$ %.2f")
            })
    else:
        st.info("N√£o h√° dados de aquisi√ß√£o para o per√≠odo.")
    

    st.header("Demografia do P√∫blico")
    col1, col2, col3 = st.columns(3)

    # --- Gr√°fico 1: G√™nero (Rosca) ---
    with col1:
        gender_response = run_ga_report(client, PROPERTY_ID,
            [Dimension(name="userGender")], [Metric(name="activeUsers")],
            start_date, end_date)
        
        if gender_response and gender_response.rows:
            df_gender = pd.DataFrame([{'G√™nero': r.dimension_values[0].value, 'Usu√°rios': int(r.metric_values[0].value)} for r in gender_response.rows])

            df_gender = df_gender[df_gender['G√™nero'] != 'unknown']    

            fig_gender = px.pie(df_gender, names='G√™nero', values='Usu√°rios', title='Distribui√ß√£o por G√™nero', hole=0.4)
            st.plotly_chart(fig_gender, use_container_width=True)

    # --- Gr√°fico 2: Idade (Barras) ---
    with col2:
        age_response = run_ga_report(client, PROPERTY_ID,
            [Dimension(name="userAgeBracket")], [Metric(name="activeUsers")],
            start_date, end_date)
            
        if age_response and age_response.rows:
            df_age = pd.DataFrame([{'Faixa Et√°ria': r.dimension_values[0].value, 'Usu√°rios': int(r.metric_values[0].value)} for r in age_response.rows])

            # Remove a faixa et√°ria desconhecida, se existir
            df_age = df_age[df_age['Faixa Et√°ria'] != 'unknown']

            fig_age = px.bar(
                df_age.sort_values("Usu√°rios", ascending=True), 
                y='Faixa Et√°ria', 
                x='Usu√°rios', 
                orientation='h', 
                title='Distribui√ß√£o por Idade',
                text='Usu√°rios',
                labels={'Usu√°rios': 'N√∫mero de Usu√°rios', 'Faixa Et√°ria': 'Faixa Et√°ria'}
            )
            fig_age.update_traces(texttemplate='%{text:.2s}', textposition='inside')
            fig_age.update_layout(yaxis_title=None)
            st.plotly_chart(fig_age, use_container_width=True)

    # --- Gr√°fico 3: Cidade (Barras) ---
    with col3:
        city_response = run_ga_report(client, PROPERTY_ID,
            [Dimension(name="city")], [Metric(name="activeUsers")],
            start_date, end_date, limit=10, order_bys=[{'metric': {'metric_name': 'activeUsers'}, 'desc': True}])
            
        if city_response and city_response.rows:
            df_city = pd.DataFrame([{'Cidade': r.dimension_values[0].value, 'Usu√°rios': int(r.metric_values[0].value)} for r in city_response.rows])
            fig_city = px.bar(
                df_city.sort_values("Usu√°rios", ascending=True), 
                y='Cidade', 
                x='Usu√°rios', 
                orientation='h', 
                title='Top 10 Cidades',
                text='Usu√°rios',
                labels={'Usu√°rios': 'N√∫mero de Usu√°rios', 'Cidade': 'Cidade'}
            )
            fig_city.update_traces(texttemplate='%{text:.2s}')
            fig_city.update_layout(yaxis_title=None)
            st.plotly_chart(fig_city, use_container_width=True)

    st.divider()
    st.header("üìÑ Engajamento por P√°gina")

    # Pede as m√©tricas necess√°rias para o c√°lculo
    page_response = run_ga_report(client, PROPERTY_ID,
        [Dimension(name="pageTitle")],
        [Metric(name="screenPageViews"), Metric(name="userEngagementDuration"), Metric(name="activeUsers")],
        start_date, end_date, limit=20, # Top 20 p√°ginas
        order_bys=[{'metric': {'metric_name': 'screenPageViews'}, 'desc': True}])

    if page_response and page_response.rows:
        page_rows = []
        for r in page_response.rows:
            views = int(r.metric_values[0].value)
            total_engagement = float(r.metric_values[1].value)
            users = int(r.metric_values[2].value)
            # Calcula o tempo m√©dio e formata
            avg_time = (total_engagement / users) if users > 0 else 0
            minutos, segundos = divmod(int(avg_time), 60)
            
            page_rows.append({
                'T√≠tulo da P√°gina': r.dimension_values[0].value,
                'Visualiza√ß√µes': views,
                'Tempo M√©dio de Engajamento': f"{minutos:02d}:{segundos:02d}"
            })
            
        df_pages = pd.DataFrame(page_rows)
        st.dataframe(df_pages, use_container_width=True, hide_index=True)

    st.divider()

    st.header("Tecnologia de Acesso")
    col1, col2 = st.columns(2)
        
    # --- Gr√°fico 1: Categoria de Dispositivo (Rosca) ---
    with col1:
        device_response = run_ga_report(client, PROPERTY_ID,
            [Dimension(name="deviceCategory")], [Metric(name="activeUsers")],
            start_date, end_date)
        
        if device_response and device_response.rows:
            df_device = pd.DataFrame([{'Dispositivo': r.dimension_values[0].value, 'Usu√°rios': int(r.metric_values[0].value)} for r in device_response.rows])
            fig_device = px.pie(df_device, names='Dispositivo', values='Usu√°rios', title='Acessos por Dispositivo', hole=0.4)
            st.plotly_chart(fig_device, use_container_width=True)

    # --- Gr√°fico 2: Sistema Operacional (Barras) ---
    with col2:
        os_response = run_ga_report(client, PROPERTY_ID,
            [Dimension(name="operatingSystem")], [Metric(name="activeUsers")],
            start_date, end_date, limit=10, order_bys=[{'metric': {'metric_name': 'activeUsers'}, 'desc': True}])
            
        if os_response and os_response.rows:
            df_os = pd.DataFrame([{'Sistema': r.dimension_values[0].value, 'Usu√°rios': int(r.metric_values[0].value)} for r in os_response.rows])
            fig_os = px.bar(
                df_os.sort_values("Usu√°rios", ascending=True), 
                y='Sistema', 
                x='Usu√°rios', 
                orientation='h', 
                title='Top 10 Sistemas Operacionais',
                text='Usu√°rios',
                labels={'Usu√°rios': 'N√∫mero de Usu√°rios', 'Sistema': 'Sistema Operacional'}
            )
            fig_os.update_traces(texttemplate='%{text:.2s}')
            fig_os.update_layout(yaxis_title=None)
            st.plotly_chart(fig_os, use_container_width=True)

    st.divider()

    # ==============================================================================
    # NOVA AN√ÅLISE: AUDITORIA DE CAMPANHAS (CRM vs GA4)
    # ==============================================================================
    TIMEZONE = 'America/Sao_Paulo'
    st.header("üïµÔ∏è Auditoria de Convers√µes com GCLID (Fonte: CRM)")
    st.info("Esta tabela mostra as oportunidades do seu CRM que possuem um GCLID registrado.")

    # Inicializa cache
    if 'gclid_cache' not in st.session_state:
        try:
            st.session_state.gclid_cache = load_gclid_cache()
            
            # Adicione esta verifica√ß√£o
            if not st.session_state.gclid_cache:
                st.warning("‚ö†Ô∏è Cache de GCLIDs vazio - verifique o banco de dados")
                st.stop()
                
        except Exception as e:
            st.error(f"‚ùå Falha ao carregar cache: {str(e)}")
            st.stop()

    try:
        # 1. Carrega os dados do banco de dados
        df_conversoes_db = carregar_dados("consultas/oportunidades/oportunidades.sql")
        df_conversoes_db['criacao'] = pd.to_datetime(df_conversoes_db['criacao']).dt.tz_localize(TIMEZONE, ambiguous='infer')

        # 2. Aplica filtros
        start_date_aware = pd.Timestamp(start_date, tz=TIMEZONE)
        end_date_aware = pd.Timestamp(end_date, tz=TIMEZONE) + pd.Timedelta(days=1)

        df_conversoes_filtrado = df_conversoes_db[
            (df_conversoes_db['criacao'] >= start_date_aware) &
            (df_conversoes_db['criacao'] < end_date_aware) &
            (df_conversoes_db['empresa'] == "Degrau") &
            (df_conversoes_db['gclid'].notnull()) & 
            (df_conversoes_db['gclid'] != '')
        ].copy()

        # Compatibilidade entre nomes de colunas (utm_campaign vs campanha)
        if 'campanha' not in df_conversoes_filtrado.columns:
            if 'utm_campaign' in df_conversoes_filtrado.columns:
                df_conversoes_filtrado = df_conversoes_filtrado.rename(columns={
                    'utm_campaign': 'campanha'
                })
            else:
                df_conversoes_filtrado['campanha'] = pd.NA
                st.warning("‚ö†Ô∏è Coluna de campanha n√£o encontrada no CRM (campanha/utm_campaign).")
        
        if not df_conversoes_filtrado.empty:
            # Prepara DataFrame para exibi√ß√£o
            df_display = df_conversoes_filtrado[[
                'criacao', 'campanha', 'gclid', 'etapa', 
                'oportunidade', 'cliente_id', 'name',
                'telefone', 'email', 'origem',
                'modalidade', 'unidade'
            ]].rename(columns={
                'criacao': 'Data da Convers√£o',
                'campanha': 'Campanha (UTM)',
                'gclid': 'GCLID',
                'etapa': 'Etapa',
                'oportunidade': 'ID Oportunidade',
                'name': 'Nome Cliente',
                'unidade': 'Unidade'
            })
            
            # Adiciona coluna de campanha do Google Ads
            df_display['Campanha (Google Ads)'] = df_display['GCLID'].map(
                lambda x: get_campaign_for_gclid(x) or 'N√£o consultado'
            )
            
            # Exibe tabela
            st.dataframe(
                df_display.sort_values('Data da Convers√£o', ascending=False),
                use_container_width=True,
                hide_index=True,
                column_config={
                    "Data da Convers√£o": st.column_config.DatetimeColumn(
                        format="D/MM/YYYY HH:mm"
                    )
                }
            )
            
            # Bot√£o de consulta
            if st.button("üì° Consultar Campanhas no Google Ads", type="primary"):
                gclid_date_dict = {
                    row['gclid']: row['criacao'].date()
                    for _, row in df_conversoes_filtrado.iterrows()
                    if pd.notna(row['gclid']) and row['gclid'] != ''
                }
                
                gads_client, customer_id = get_google_ads_client()
                if gads_client:
                    with st.spinner(f"Consultando {len(gclid_date_dict)} GCLIDs..."):
                        result = get_campaigns_for_gclids_with_date(
                            gads_client, customer_id, gclid_date_dict
                        )
                        
                        if result is not None:
                            st.success("Consulta conclu√≠da! Atualizando tabela...")
                            st.rerun()
                else:
                    st.error("Falha na conex√£o com Google Ads")

            st.divider()
            st.header("üìä An√°lise de Campanhas por Etapa do Funil")
            st.info("Esta an√°lise utiliza os dados do CRM com GCLID para mostrar a distribui√ß√£o de oportunidades por etapa para cada campanha do Google Ads. Campanhas com GCLID n√£o consultado ou n√£o encontrado s√£o omitidas.")

            # Filtra para usar apenas campanhas que foram encontradas no Google Ads
            df_analise_etapas = df_display.copy()

            if not df_analise_etapas.empty:
                # Cria a tabela pivotada
                tabela_etapas = pd.pivot_table(
                    df_analise_etapas,
                    index='Campanha (Google Ads)',
                    columns='Etapa',
                    values='GCLID',
                    aggfunc='count',
                    fill_value=0
                )

                # Adiciona uma coluna de Total
                tabela_etapas['Total'] = tabela_etapas.sum(axis=1)

                # Ordena pela coluna Total, do maior para o menor
                tabela_etapas_ordenada = tabela_etapas.sort_values(by='Campanha (Google Ads)', ascending=False)

                # --- ADICIONA A LINHA DE TOTAL GERAL ---
                # Calcula a soma de cada coluna
                total_geral = tabela_etapas_ordenada.sum().to_frame().T
                # Define o nome do √≠ndice para a linha de total
                total_geral.index = ['TOTAL GERAL']

                # Concatena a linha de total ao DataFrame
                tabela_final_com_total = pd.concat([tabela_etapas_ordenada, total_geral])

                # Exibe a tabela com o total geral
                st.dataframe(tabela_final_com_total, use_container_width=True)
                
                # ===============================================================================
                # NOVA SE√á√ÉO: AN√ÅLISES DETALHADAS DE CAMPANHAS E ETAPAS
                # ===============================================================================
                st.divider()
                st.header("üîç An√°lises Detalhadas de Campanhas e Etapas")
                st.info("Esta se√ß√£o oferece visualiza√ß√µes personaliz√°veis sobre a distribui√ß√£o de campanhas por etapas do funil de convers√£o.")
                
                # Filtra para usar apenas campanhas e etapas que existem no per√≠odo selecionado
                df_periodo = df_display.copy()
                
                # Lista de campanhas dispon√≠veis no per√≠odo (excluindo o total geral)
                campanhas_disponiveis_periodo = list(tabela_etapas.index)
                campanhas_disponiveis_periodo = [c for c in campanhas_disponiveis_periodo if c != 'TOTAL GERAL']
                
                # Lista de etapas dispon√≠veis no per√≠odo (todas as colunas exceto 'Total')
                etapas_disponiveis_periodo = list(df_periodo['Etapa'].unique())
                
                # --- FILTROS EM EXPANDER ---
                with st.expander("üìã Filtros para An√°lise Detalhada", expanded=True):
                    col1, col2 = st.columns(2)
                    
                    # Filtro de Campanhas (multi-select)
                    with col1:
                        campanhas_selecionadas = st.multiselect(
                            "Selecione as Campanhas:",
                            options=campanhas_disponiveis_periodo,
                            default=campanhas_disponiveis_periodo[:20] if len(campanhas_disponiveis_periodo) > 20 else campanhas_disponiveis_periodo
                        )
                    
                    # Filtro de Etapas (multi-select)
                    with col2:
                        etapas_selecionadas = st.multiselect(
                            "Selecione as Etapas:",
                            options=etapas_disponiveis_periodo,
                            default=etapas_disponiveis_periodo
                        )
                
                # Aplicar filtros ao dataframe
                if campanhas_selecionadas and etapas_selecionadas:
                    # Filtra apenas as campanhas e etapas selecionadas
                    df_filtro_campanhas = df_periodo[
                        (df_periodo['Campanha (Google Ads)'].isin(campanhas_selecionadas)) &
                        (df_periodo['Etapa'].isin(etapas_selecionadas))
                    ]
                    
                    # --- GR√ÅFICOS ---
                    col1, col2 = st.columns(2)
                    
                    # 1. Gr√°fico de Barras para Campanhas (sem segmenta√ß√£o por etapa)
                    with col1:
                        # Conta oportunidades por campanha
                        contagem_campanhas = df_filtro_campanhas.groupby('Campanha (Google Ads)').size().reset_index(name='Contagem')
                        contagem_campanhas = contagem_campanhas.sort_values('Contagem', ascending=True)
                        
                        # Cria o gr√°fico de barras
                        fig_campanhas = px.bar(
                            contagem_campanhas,
                            x='Contagem',
                            y='Campanha (Google Ads)',
                            orientation='h',
                            title="Distribui√ß√£o de Campanhas",
                            labels={'Contagem': 'N√∫mero de Oportunidades', 'Campanha (Google Ads)': 'Campanha'},
                            color_discrete_sequence=['#2E86C1']  # Cor azul para todas as barras
                        )
                        
                        # Ajusta o layout
                        fig_campanhas.update_layout(
                            showlegend=False,
                            height=400 + (len(campanhas_selecionadas) * 30)  # Ajusta altura baseado no n√∫mero de campanhas
                        )
                        
                        st.plotly_chart(fig_campanhas, use_container_width=True)
                    
                    # 2. Gr√°fico de Pizza para Etapas
                    with col2:
                        # Filtra os dados
                        df_filtro_etapas = df_periodo[
                            (df_periodo['Campanha (Google Ads)'].isin(campanhas_selecionadas)) &
                            (df_periodo['Etapa'].isin(etapas_selecionadas))
                        ]
                        
                        # Conta oportunidades por etapa
                        contagem_etapas = df_filtro_etapas.groupby('Etapa').size().reset_index(name='Contagem')
                        
                        # Cria o gr√°fico de pizza
                        fig_etapas = px.pie(
                            contagem_etapas,
                            names='Etapa',
                            values='Contagem',
                            title="Distribui√ß√£o de Oportunidades por Etapa",
                            hole=0.4  # Cria um gr√°fico de rosca
                        )
                        
                        # Ajusta o layout
                        fig_etapas.update_layout(
                            legend_title_text='Etapa',
                            height=500
                        )
                        
                        st.plotly_chart(fig_etapas, use_container_width=True)
                else:
                    st.warning("Selecione pelo menos uma campanha e uma etapa para visualizar os gr√°ficos.")
            else:
                st.warning("N√£o h√° dados de campanhas consultadas no Google Ads para gerar a an√°lise por etapa. Clique no bot√£o 'Consultar Campanhas no Google Ads' acima.")

    except Exception as e:
        st.error(f"Erro ao carregar dados: {str(e)}")